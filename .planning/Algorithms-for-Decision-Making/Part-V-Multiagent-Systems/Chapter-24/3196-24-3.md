---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: (24.3)
---

# (24.3)

_Source page: 517_



∈A


Algorithm 24.3 provides an implementation of this.


© 2022 Massachusetts Institute of Technology, shared under a Creative Commons CC-BY-NC-ND license.


2025-09-21 10:49:56-07:00, comments to bugs@algorithmsbook.com


496


chapter 24. multiagent reasoning


Algorithm 24.2. A policy associ-


struct


SimpleGamePolicy


ated with an agent is represented


# dictionary mapping actions to probabilities


by a dictionary that maps actions


to probabilities. There are differ-


function


SimpleGamePolicy


::


Base


Generator


ent ways to construct a policy. One


return


SimpleGamePolicy


Dict


))


way is to pass in a dictionary direc-


end


tory, in which case the probabilities


function


SimpleGamePolicy


::


Dict


are normalized. Another way is to


vs


collect


values


))


pass in a generator that creates this


vs


/=


sum


vs


dictionary. We can also construct a


return


new


Dict


=>


for


in


zip


keys


),


vs


)))


policy by passing in an action, in


end


which case it assigns probability


to that action. If we have an individ-


SimpleGamePolicy


ai


new


Dict


ai


=>


1.0


))


ual policy


πi


, we can call


πi


ai


end


to compute the probability the pol-


icy associates with action


ai


. If we


πi


::


SimpleGamePolicy


)(


ai


get


πi


ai


0.0


call


πi


()


, then it will return a ran-


dom action according to that policy.


function


πi


::


SimpleGamePolicy


)()


We can use


joint


to construct


SetCategorical


collect


keys


πi


)),


collect


values


πi


)))


the joint action space from


. We


return


rand


can use


utility


to com-


end


pute the utility associated with ex-


ecuting joint policy


in the game


joint


vec


collect


product