---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: (27.4)
---

# (27.4)

_Source page: 570_



123


34


Sensor network and target tracking problems are often framed as ND-POMDPs.


Figure 27.1. An ND-POMDP struc-


The ND-POMDP model is similar to the transition and observation indepen-


ture with five agents. There are


dent Dec-MDP model, but it does not make the joint full observability assumption.


three hyperedges: one involving


agents


, and


; another involv-


Even if all observations are shared, the true state of the world may not be known.


ing agents


and


; and another in-


Furthermore, even with factored transitions and observations, a policy in an ND-


volving agent


on its own.


POMDP is a mapping from observation histories to actions, unlike the transition


and observation Dec-MDP case, in which policies are mappings from local states


to actions. The worst-case complexity remains the same as for a Dec-POMDP, but


algorithms for ND-POMDPs are typically much more scalable in the number of


agents. Scalability can increase as the coordination graph becomes less connected.


If the agents are able to communicate their actions and observations perfectly


without penalty, then they are able to maintain a collective belief state. This


model is called a


multiagent MDP