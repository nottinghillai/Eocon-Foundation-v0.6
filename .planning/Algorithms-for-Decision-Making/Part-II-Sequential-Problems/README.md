# Part II: Sequential Problems

## Description
This part focuses on sequential decision problems modeled as Markov decision processes (MDPs).
Topics include exact and approximate solution methods, online planning, policy search,
policy gradient methods, actor-critic algorithms, and policy validation techniques.

## Chapters

### Chapter 7: Exact Solution Methods

[View Chapter →](Chapter-07/README.md) (52 files)

### Chapter 8: Approximate Value Functions

[View Chapter →](Chapter-08/README.md) (29 files)

### Chapter 9: Online Planning

[View Chapter →](Chapter-09/README.md) (27 files)

### Chapter 10: Policy Search

[View Chapter →](Chapter-10/README.md) (67 files)

### Chapter 11: Policy Gradient Estimation

[View Chapter →](Chapter-11/README.md) (63 files)

### Chapter 12: Policy Gradient Optimization

[View Chapter →](Chapter-12/README.md) (42 files)

### Chapter 13: Actor-Critic Methods

[View Chapter →](Chapter-13/README.md) (50 files)

### Chapter 14: Policy Validation

[View Chapter →](Chapter-14/README.md) (33 files)


## Navigation

- [← Back to Main Index](../README.md)

---
