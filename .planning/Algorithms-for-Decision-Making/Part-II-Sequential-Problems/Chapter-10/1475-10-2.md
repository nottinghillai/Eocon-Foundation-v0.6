---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: (10.2)
---

# (10.2)

_Source page: 236_



where


is the probability density associated with trajectory


when following


policy


, starting from initial state distribution


. The


trajectory reward


is the


discounted return associated with


. Figure 10.1 illustrates the computation of


in terms of trajectories sampled from an initial state distribution.


Figure 10.1. The utility associated


Monte Carlo policy evaluation


(algorithm 10.1) involves approximating equa-


with a policy from an initial state


distribution is computed from the


tion (10.2) with


trajectory rollouts of


return associated with all possible


trajectories under the given policy,