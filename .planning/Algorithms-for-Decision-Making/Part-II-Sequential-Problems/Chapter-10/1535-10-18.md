---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: (10.18)
---

# (10.18)

_Source page: 246_



∼N


16


This technique was implemented


by T. Salimans, J. Ho, X. Chen, S.


Algorithm 10.6 provides an implementation of this strategy. This implemen-


Sidor, and I. Sutskever, “Evolution


15


tation incorporates


mirrored sampling


We sample


/2


values from the search


Strategies as a Scalable Alterna-


tive to Reinforcement Learning,”


distribution and then generate the other


/2


samples by mirroring them about


2017. arXiv: 1703 . 03864v2. They


16


the mean. Mirrored samples reduce the variance of the gradient estimate.


The


included other techniques as well,


including weight decay.


benefit of using this technique is shown in figure 10.8.


© 2022 Massachusetts Institute of Technology, shared under a Creative Commons CC-BY-NC-ND license.


2025-09-21 10:49:56-07:00, comments to bugs@algorithmsbook.com


10.6. isotropic evolutionary strategies


225


Algorithm 10.6.


An evolution


struct


IsotropicEvolutionStrategies


strategies method for updating


# initial mean


an isotropic multivariate Gaus-


# initial standard deviation


sian search distribution with mean


# number of samples


and covariance


over pol-


# step factor


icy parameterizations for a policy


k_max


# number of iterations


end


. This implementation also


takes a policy evaluation function


function


optimize_dist


::


IsotropicEvolutionStrategies


, a step factor


, and an itera-


k_max


k_max


tion count


k_max


. In each iteration,


length


parameterization samples are


ws


evolution_strategy_weights


div


))


drawn and mirrored and are then


for


in 1


k_max


used to estimate the search gradi-


ϵs


randn


for


in 1


div


)]


ent.


append!


ϵs


ϵs


# weight mirroring


us


for


in


ϵs


sp


sortperm


us


rev


true


sum


ϵs


for


in


zip


ws


sp


))


+=


end


return


MvNormal


end