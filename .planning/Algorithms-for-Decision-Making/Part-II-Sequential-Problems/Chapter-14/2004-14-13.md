---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: (14.13)
---

# (14.13)

_Source page: 309_



traj


Â© 2022 Massachusetts Institute of Technology, shared under a Creative Commons CC-BY-NC-ND license.


2025-09-21 10:49:56-07:00, comments to bugs@algorithmsbook.com


288


chapter 14. policy validation


If


traj


is nonnegative, then the denominator is exactly the same as the metric that


10


we are trying to estimate in equation (14.1).


Although equation (14.13) is generally not practical to compute exactly (this


is why we are using importance sampling in the first place), it can provide some


intuition as to how to use our domain expertise to construct a proposal distribution.


m/s


It is common to bias the initial state distribution or the transition model slightly


toward more important trajectories, such as toward collision.


10


To illustrate the construction of an importance distribution, we will use the


200


200


100


100


optimal policy for the collision avoidance problem in example 14.1. Instead


of starting at


40 s


, we will start the aircraft closer, with


20 s


, to


col


col


Figure 14.2. Proposal distribution


make the collision avoidance problem more challenging. The true distribution


generated from the probability of


has