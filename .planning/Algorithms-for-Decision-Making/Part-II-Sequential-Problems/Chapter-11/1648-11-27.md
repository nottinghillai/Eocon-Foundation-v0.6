---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: (11.27)
---

# (11.27)

_Source page: 263_



log


Algorithm 11.5.


A method that


struct


RewardToGoGradient


uses reward-to-go for estimating


# problem


a policy gradient of a policy


# initial state distribution


for an MDP


with initial state dis-


# depth


tribution


. The gradient with re-


# number of samples


spect to the parameterization vec-


∇logπ


# gradient of log likelihood


end


tor


is estimated from


rollouts to


depth


using the log policy gradi-


function


gradient


::


RewardToGoGradient


ent


∇logπ


∇logπ


∇logπ


πθ


sum


-1


for


,(


))


in


zip


end


]))


∇U


sum


∇logπ


for


, (


))


in


enumerate


))


return


mean


∇U


simulate


rand


),


πθ


))


for


in 1


end