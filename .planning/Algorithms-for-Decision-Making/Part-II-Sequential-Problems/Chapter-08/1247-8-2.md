---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: (8.2)
---

# (8.2)

_Source page: 184_



This chapter discusses how we can apply dynamic programming at a finite set


of states


1:


to arrive at a parametric approximation of the value function over


the full state space. Different schemes can be used to generate this set. If the state


space is relatively low-dimensional, we can define a grid. Another approach is to


use random sampling from the state space. However, some states are more likely to


be encountered than others and are therefore more important in constructing the


value function. We can bias the sampling toward more important states by running


Several other categories of ap-


simulations with some policy (perhaps initially random), from a plausible set of


proaches for optimizing value func-


initial states.


tion approximations are surveyed


An iterative approach can be used to enhance our approximation of the value


by A. Geramifard, T. J. Walsh, S.


Tellex, G. Chowdhary, N. Roy, and


function at the states in


. We alternate between improving our value estimates at


J. P. How, “A Tutorial on Linear


through dynamic programming and refitting our approximation at those states.


Function Approximators for Dy-


Algorithm 8.1 provides an implementation where the dynamic programming


namic Programming and Rein-


forcement Learning,”


Foundations


step consists of Bellman backups as done in value iteration (see section 7.5). A


and Trends in Machine Learning


similar algorithm can be created for action value approximations


vol. 6, no. 4, pp. 375–451, 2013.


Algorithm 8.1. Approximate value


struct


ApproximateValueIteration


iteration for an MDP


with the


Uθ


# initial parameterized value function that supports fit!


parameterized value function ap-


# set of discrete states for performing backups


proximation


Uθ


. We perform back-


k_max


# maximum number of iterations


ups (defined in algorithm 7.7) at


end


the states in


to obtain a vec-


function


solve


::


ApproximateValueIteration


::


MDP


tor of utilities


. We then call


Uθ


k_max


Uθ


k_max


fit!


Uθ


, which modifies


for


in 1


k_max


the parametric representation


Uθ


backup


Uθ


for


in


to better match the value of the


fit!


Uθ


states in


to the utilities in


. Dif-


end


ferent parametric approximations


return


ValueFunctionPolicy


Uθ


have different implementations for


end


fit!


All of the parametric representations discussed in this chapter can be used


with algorithm 8.1. To be used with that algorithm, a representation needs to


support the evaluation of


and the fitting of


to estimates of the utilities at


the points in


© 2022 Massachusetts Institute of Technology, shared under a Creative Commons CC-BY-NC-ND license.


2025-09-21 10:49:56-07:00, comments to bugs@algorithmsbook.com


8.2. nearest neighbor


163


We can group the parametric representations into two categories. The first


category includes


local approximation


methods, where


corresponds to the values


at the states in


. To evaluate


at an arbitrary state


, we take a weighted


sum of the values stored in


. The second category includes


global approximation


methods, where


is not directly related to the values at the states in


. In fact,


may have far fewer or even far more components than there are states in


Both local approximation and many global approximations can be viewed as a


linear function approximation