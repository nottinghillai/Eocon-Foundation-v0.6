---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: (17.22)
---

# (17.22)

_Source page: 370_



grad


where


, and


is the


th experience tuple in a random batch of size


grad


Experience replay allows experience tuples to contribute to learning multiple


times, thereby increasing data efficiency. Furthermore, sampling uniformly at


random from the replay memory breaks apart otherwise correlated sequences that


are obtained from rollouts, thereby reducing the variance of the gradient estimate.


Experience replay stabilizes the learning process by retaining information from


previous policy parameterizations.


Algorithm 17.6 shows how to incorporate experience replay into


-learning


with action value function approximation. Example 17.4 shows how to apply this


approach to a simple regulator problem.