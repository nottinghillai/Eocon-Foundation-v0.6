---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: (D.6)
---

# (D.6)

_Source page: 607_



where the positive scalar


controls the strength of the parameter regularization.


The scalar is often quite small, with values as low as


10


, to minimize the degree


to which matching the training set is sacrificed by introducing regularization.


Â© 2022 Massachusetts Institute of Technology, shared under a Creative Commons CC-BY-NC-ND license.


2025-09-21 10:49:56-07:00, comments to bugs@algorithmsbook.com


586


appendix d. neural representations


Example D.2. How reverse accu-


Recall the neural network and loss function from example D.1. Here we have


mulation is used to compute pa-


drawn the computational graph for the loss calculation:


rameter gradients given training


data.


pred


true


Reverse accumulation begins with a forward pass, in which the compu-


tational graph is evaluated. We will again use