---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: Summary
---

# Summary

_Source page: 248_



Monte Carlo policy evaluation involves computing the expected utility associ-


ated with a policy using a large number of rollouts from states sampled from


an initial state distribution.


Local search methods, such as the Hooke-Jeeves method, improve a policy


based on small, local changes.


Genetic algorithms maintain a population of points in the parameter space,


recombining them in different ways in attempt to drive the population toward


a global optimum.


The cross entropy method iteratively improves a search distribution over policy


parameters by refitting the distribution to elite samples at each iteration.


Evolutionary strategies attempt to improve the search distribution using gradi-


ent information from samples from that distribution.


Isotropic evolutionary strategies make the assumption that the search distribu-


tion is an isotropic Gaussian.