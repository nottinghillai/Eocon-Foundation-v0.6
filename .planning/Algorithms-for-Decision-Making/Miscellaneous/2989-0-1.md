---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: 0, 1
---

# 0, 1

_Source page: 484_



. Each particle


represents


+=


s′


s′


a particular scenario


at a particu-


if


lar depth


, referring to the


th row


return


s′


and


th column of


end


end


return


last


),


last


end


function


possible_observations


[]


for


in


s′


successor


push!


end


return


unique


end


function


update


b′


[]


for


in


s′


o′


successor


if


==


o′


push!


b′


DeterminizedParticle


s′


))


end


end


return


b′


end


© 2022 Massachusetts Institute of Technology, shared under a Creative Commons CC-BY-NC-ND license.


2025-09-21 10:49:56-07:00, comments to bugs@algorithmsbook.com


22.7. gap heuristic search


463


Algorithm 22.3.


An implemen-


struct


DeterminizedSparseTreeSearch


tation


of


determinized


sparse


# problem


tree search, a modification of


# depth


forward


search,


for


POMDPs.


# m×d determinizing matrix


The policy takes a belief


in the


# value function to use at leaf nodes


form of a vector of probabilities,


end


which is approximated by a vector


function


determinized_sparse_tree_search


of


determinized


particles


by


determinized_belief


if


==


return


nothing


))


end


best


nothing


=-


Inf


for


in


sum


for


in


length


for


in


possible_observations


Poba


sum


sum


s′


s′


for


s′


in


for


in


length


b′


update


u′


determinized_sparse_tree_search


b′


-1


).


+=


Poba


u′


end


if


best


best


end


end


return


best


end


function


determinized_belief


particles


[]


for


in 1


rand


SetCategorical


))


push!


particles


DeterminizedParticle


))


end


return


particles


end


function


::


DeterminizedSparseTreeSearch


)(


particles


determinized_belief


size


))


return


determinized_sparse_tree_search


particles


).


end


© 2022 Massachusetts Institute of Technology, shared under a Creative Commons CC-BY-NC-ND license.


2025-09-21 10:49:56-07:00, comments to bugs@algorithmsbook.com


464


chapter 22. online belief state planning


lookahead using an approximate value function. Algorithm 22.4 provides an


There are a variety of differ-


implementation.


ent heuristic search algorithms for


The initial lower- and upper-bound values used in heuristic search play an


POMDPs that attempt to mini-


important role in the algorithm’s performance. Example 22.6 uses a random


mize the gap. For example, see S.


Ross and B. Chaib-draa, “AEMS:


rollout policy for the lower bound


. A rollout is not guaranteed to produce a


An Anytime Online Search Algo-


lower bound, of course, because it is based on a single trial up to a fixed depth.


rithm for Approximate Policy Re-


finement in Large POMDPs,” in


In-


As the number of samples increases, it will converge to a true lower bound. That


ternational Joint Conference on Artifi-


example uses the best-action best-state upper bound from equation (21.2). Many


cial Intelligence (IJCAI)


, 2007. This


other forms of upper and lower bounds exist that can provide faster convergence,


implementation is similar to the


one used by DESPOT, referenced


but at the cost of run time and implementation complexity. For example, using


in the previous section.


the fast informed bound (algorithm 21.3) for the upper bound can improve


exploration and help reduce the gap. For the lower bound, we can use a problem-


specific rollout policy to better guide the search.