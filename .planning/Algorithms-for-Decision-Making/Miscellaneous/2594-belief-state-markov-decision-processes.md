---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: Belief-State Markov Decision Processes
---

# Belief-State Markov Decision Processes

_Source page: 429_



Any POMDP can be viewed as an MDP that uses beliefs as states, also called a


K. J. Åström, “Optimal Control of


belief-state MDP


The state space of a belief-state MDP is the set of all beliefs


Markov Processes with Incomplete


The action space is identical to that of the POMDP.


State Information,”


Journal of Math-


The reward function for a belief-state MDP depends on the belief and action


ematical Analysis and Applications


vol. 10, no. 1, pp. 174–205, 1965.


taken. It is simply the expected value of the reward. For a discrete state-space, it


is given by