---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: Exact Solution Methods
---

# Exact Solution Methods

_Source page: 155_



Such models were originally stud-


This chapter introduces a model known as a


Markov decision process


MDP


) to


ied in the 1950s. R. E. Bellman,


Dy-


represent sequential decision problems where the effects of our actions are uncer-


namic Programming


. Princeton Uni-


tain.


We begin with a description of the model, which specifies both the stochastic


versity Press, 1957. A modern treat-


ment can be found in M. L. Put-


dynamics of the system as well as the utility associated with its evolution. Dif-


erman,


Markov Decision Processes:


ferent algorithms can be used to compute the utility associated with a decision


Discrete Stochastic Dynamic Program-


ming


. Wiley, 2005.


strategy and to search for an optimal strategy. Under certain assumptions, we can


find exact solutions to MDPs. Later chapters will discuss approximation methods


that tend to scale better to larger problems.