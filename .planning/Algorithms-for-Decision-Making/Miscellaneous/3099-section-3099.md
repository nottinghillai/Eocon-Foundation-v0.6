---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: = [
---

# = [

_Source page: 505_



trollers with a fixed size of


set


to


, and


. Each row shows the


controller utility (


policy and its corresponding utili-


ties (alpha vectors) on the left and


20


right, respectively. The stochastic


controllers are shown as circles,


40


ignore


crying, quiet


with the most likely action in the


middle. The outgoing edges show


successor node selections given an


60


observation. The stochasticity in


0.2


0.6


0.8


0.4


node actions and successors are


hungry


shown as opacity (more opaque is


higher probability, more transpar-


ent is lower probability).


controller utility (


ignore


quiet


20


40


crying


crying, quiet


60


0.2


0.6


0.8


0.4


feed


hungry


controller utility (


ignore


crying, quiet


quiet


feed


20


40


crying


crying, quiet


60


0.2


0.6


0.8


0.4


feed


hungry


With


, the optimal policy is to simply ignore forever. With


, the


optimal policy is to ignore until crying is observed, at which point the best


action is to feed the baby, and then return to ignoring. This policy is close to


optimal for the infinite horizon crying baby POMDP. With


, the optimal


policy essentially remains unchanged from when


Â© 2022 Massachusetts Institute of Technology, shared under a Creative Commons CC-BY-NC-ND license.


2025-09-21 10:49:56-07:00, comments to bugs@algorithmsbook.com


484


chapter 23. controller abstractions


We define the transition function with a controller, which has a state space