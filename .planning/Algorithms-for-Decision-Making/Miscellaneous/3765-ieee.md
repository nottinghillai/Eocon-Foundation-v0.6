---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: IEEE
---

# IEEE

_Source page: 609_



, vol. 86, no. 11, pp. 2278–2324,


parameters tend to be receptive to local textures in much the same way that the


1998.


neurons in the visual cortex respond to stimuli in their receptive fields.


Figure D.7. A convolutional layer


repeatedly applies filters across an


input tensor, such as an image, to


filter


produce an output tensor. This il-


lustration shows how each applica-


filter output


receptive field


tion of the filter acts like a small,


fully connected layer applied to


a small receptive field to produce


a single entry in the output ten-


input tensor


sor. Each filter is shifted across


the input according to a prescribed


stride. The resulting output has as


many layers as there are filters.


The convolutional layer consists of a set of


features


, or


kernels


, each of which is


equivalent to a fully connected layer into which one can input a smaller region


of the input tensor. A single kernel is being applied once in figure D.7. These


features have full depth, meaning that if an input tensor is


, the features


will also have a third dimension of


. The features are applied many times by


sliding them over the input in both the first and second dimensions. If the


stride


is


, then all


filters are applied to every possible position and the output


dimension will be


. If the stride is


, then the filters are shifted by


in the first and second dimensions with every application, resulting in an output


of size


/2


/2


. It is common for convolutional neural networks to increase


in the third dimension and reduce in the first two dimensions with each layer.


© 2022 Massachusetts Institute of Technology, shared under a Creative Commons CC-BY-NC-ND license.


2025-09-21 10:49:56-07:00, comments to bugs@algorithmsbook.com


588


appendix d. neural representations


Convolutional layers are translation-invariant because each filter behaves the


same regardless of where in the input is applied. This property is especially useful


in spatial processing because shifts in an input image can yield similar outputs,


making it easier for neural networks to extract common features. Individual


features tend to learn how to recognize local attributes such as colors and textures.


Example D.3. A convolutional neu-


The MNIST data set contains handwritten dig-


ral network for the MNIST data set.


Y. LeCun, L. Bottou, Y. Bengio, and


its in the form of


28


28


monochromatic im-


P. Haffner, “Gradient-Based Learn-


ages. It is a often used to test image classifi-


ing Applied to Document Recog-


cation networks. To the right, we have a sam-


nition,”


Proceedings of the IEEE


vol. 86, no. 11, pp. 2278–2324, 1998.


28


28


ple convolutional neural network that takes an


MNIST image as input and produces a cate-


conv


stride


+ relu


gorical probability distribution over the


10


pos-


14


14


sible digits. Convolutional layers are used to


conv


stride


+ relu


efficiently extract features. The model shrinks


16


in the first two dimensions and expands in the


conv


stride


+ relu


third dimension (the number of features) as


32


the network depth increases. Eventually reach-


conv


stride


+ relu


ing a first and second dimension of


ensures


32


that information from across the entire image


conv


stride


+ relu


can affect every feature. The flatten operation


32


takes the


32


input and flattens it into


flatten


32


-component output. Such operations are


32


common when transitioning between convolu-


fully connected + softmax


tional and fully connected layers. This model


10


has