---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: REINFORCE, 245
---

# REINFORCE, 245

_Source page: 699_



sigma points, 387


stochastic policy, 135


reinforcement learning, 7, 15, 297


sigmoid, 32


stress testing, 289


relative entropy, 567


simple decisions, 111


strictly concave, 565


relative standard error, 285


simple game, 493


strictly convex, 565


repeated games, 493


simple regulator problem, 613


stride, 587


replay memory, 345


simplex, 168


string, 629


representation learning, 592


simplex interpolation, 168


Successive Approximations of the


response, 494


simulated annealing, 102


Reachable Space under Optimal


response policy, 519


simultaneous perturbation stochastic


Policies, 440


restricted step, 251


approximation, 234


successor distribution, 471


return, 134, 599


singular value decomposition, 174


sum-product algorithm, 53


reverse accumulation, 585


SMILe,


see


stochastic mixing iterative


sum-product variable elimination, 49


reward function, 133


learning


supervised learning, 6


reward independence, 547


smooth fictitious play, 509


support, 22f


reward shaping, 343


softmax, 583


surrogate constraint, 256


reward-to-go, 240


softmax response, 497


surrogate objective, 256


robust dynamic programming, 289


softmax response policy, 520


symbol, 630


robust model predictive control, 204


softmax strategy, 303


symmetry, 562


rock-paper-scissors, 495, 621


soft threshold, 32


rollout policy, 183


sparse reward, 341


tabu search, 103


sparse sampling, 187


target parameterizations, 274


spherical Gaussian,


see


isotropic


salvage values, 617


taxicab norm, 563


Gaussian


sample space, 562


Taylor approximation, 569


splat, 642


Sarsa, 338


Taylor expansion, 568


spread parameter, 388