---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: Summary
---

# Summary

_Source page: 111_



Parameter learning involves inferring the parameters of a probabilistic model


from data.


A maximum likelihood approach to parameter learning involves maximizing


a likelihood function, which can be done analytically for some models.


A Bayesian approach to parameter learning involves inferring a probability


distribution over the underlying parameter using Bayesâ€™ rule.


The beta and Dirichlet distributions are examples of Bayesian priors that are


easily updated with evidence.


In contrast with parametric learning, which assumes a fixed parameterization


of a probability model, nonparametric learning uses representations that grow


with the amount of data.


We can approach the problem of learning parameters from missing data using


methods such as data imputation or expectation-maximization, where we


make inferences based on observed values.