---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: Summary
---

# Summary

_Source page: 417_



Partially observable Markov decision processes (POMDPs) extend MDPs to


include state uncertainty.


The uncertainty requires agents in a POMDP to maintain a belief over their


state.


© 2022 Massachusetts Institute of Technology, shared under a Creative Commons CC-BY-NC-ND license.


2025-09-21 10:49:56-07:00, comments to bugs@algorithmsbook.com


396


chapter 19. beliefs


Example 19.6. A particle filter with


Spelunker Joe from example 19.6 now moves one tile to the east and moves


adaptive injection


α_slow