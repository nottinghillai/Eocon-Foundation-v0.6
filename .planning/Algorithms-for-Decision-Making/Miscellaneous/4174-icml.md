---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: (ICML)
---

# (ICML)

_Source page: 688_



, 2014 (cit. on p. 272).


233.


D. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou, A. Huang, A. Guez, T. Hubert,


L. Baker, M. Lai, A. Bolton, et al., “Mastering the Game of Go Without Human


Knowledge,”


Nature


, vol. 550, pp. 354–359, 2017 (cit. on p. 276).


234.


D. Silver and J. Veness, “Monte-Carlo Planning in Large POMDPs,” in


Advances in


Neural Information Processing Systems (NIPS)


, 2010 (cit. on p. 457).


235.


S. Singh, M. Kearns, and Y. Mansour, “Nash Convergence of Gradient Dynamics in


General-Sum Games,” in


Conference on Uncertainty in Artificial Intelligence (UAI)


2000 (cit. on p. 509).


236.


S. P. Singh and R. S. Sutton, “Reinforcement Learning with Replacing Eligibility


Traces,”


Machine Learning


, vol. 22, pp. 123–158, 1996 (cit. on p. 612).


237.


S. P. Singh and R. C. Yee, “An Upper Bound on the Loss from Approximate Optimal-


Value Functions,”


Machine Learning


, vol. 16, no. 3, pp. 227–233, 1994 (cit. on p. 142).


238.


R. D. Smallwood and E. J. Sondik, “The Optimal Control of Partially Observable


Markov Processes over a Finite Horizon,”


Operations Research


, vol. 21, no. 5, pp. 1071–


1088, 1973 (cit. on p. 617).


239.


T. Smith and R. G. Simmons, “Heuristic Search Value Iteration for POMDPs,” in


Conference on Uncertainty in Artificial Intelligence (UAI)


, 2004 (cit. on p. 442).


240.


E. Sonu, Y. Chen, and P. Doshi, “Decision-Theoretic Planning Under Anonymity in


Agent Populations,”


Journal of Artificial Intelligence Research


, vol. 59, pp. 725–770,


2017 (cit. on p. 534).


© 2022 Massachusetts Institute of Technology, shared under a Creative Commons CC-BY-NC-ND license.


2025-09-21 10:49:56-07:00, comments to bugs@algorithmsbook.com


references


667


241.


M. T. J. Spaan and N. A. Vlassis, “Perseus: Randomized Point-Based Value Iteration


for POMDPs,”


Journal of Artificial Intelligence Research


, vol. 24, pp. 195–220, 2005


(cit. on p. 433).


242.


J. C. Spall,


Introduction to Stochastic Search and Optimization


. Wiley, 2003 (cit. on


p. 234).


243.


D. O. Stahl and P. W. Wilson, “Experimental Evidence on Players’ Models of Other


Players,”


Journal of Economic Behavior & Organization


, vol. 25, no. 3, pp. 309–327,


1994 (cit. on p. 504).


244.


G. J. Stigler, “The Development of Utility Theory. I,”


Journal of Political Economy


vol. 58, no. 4, pp. 307–327, 1950 (cit. on p. 8).


245.


M. J. A. Strens, “A Bayesian Framework for Reinforcement Learning,” in


International


Conference on Machine Learning (ICML)


, 2000 (cit. on p. 330).


246.


F. P. Such, V. Madhavan, E. Conti, J. Lehman, K. O. Stanley, and J. Clune, “Deep


Neuroevolution: Genetic Algorithms Are a Competitive Alternative for Training


Deep Neural Networks for Reinforcement Learning,” 2017. arXiv: 1712.06567v3


(cit. on p. 215).


247.


Z. N. Sunberg and M. J. Kochenderfer, “Online Algorithms for POMDPs with Con-


tinuous State, Action, and Observation Spaces,” in


International Conference on Auto-


mated Planning and Scheduling (ICAPS)


, 2018 (cit. on p. 457).


248.


R. Sutton, “Learning to Predict by the Methods of Temporal Differences,”


Machine


Learning


, vol. 3, no. 1, pp. 9–44, 1988 (cit. on p. 341).


249.


R. S. Sutton, “Dyna, an Integrated Architecture for Learning, Planning, and React-


ing,”


SIGART Bulletin


, vol. 2, no. 4, pp. 160–163, 1991 (cit. on p. 318).


250.


R. S. Sutton and A. G. Barto,


Reinforcement Learning: An Introduction


, 2nd ed. MIT


Press, 2018 (cit. on pp. 9, 335).


251.


U. Syed and R. E. Schapire, “A Reduction from Apprenticeship Learning to Classi-


fication,” in


Advances in Neural Information Processing Systems (NIPS)


, 2010 (cit. on


p. 357).


252.


C. Szepesvári and T. Lattimore,


Bandit Algorithms


. Cambridge University Press,


2020 (cit. on p. 299).


253.


D. Szer, F. Charpillet, and S. Zilberstein, “MAA*: A Heuristic Search Algorithm for


Solving Decentralized POMDPs,” in


Conference on Uncertainty in Artificial Intelligence