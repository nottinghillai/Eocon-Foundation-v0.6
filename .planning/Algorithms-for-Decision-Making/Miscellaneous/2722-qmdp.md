---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: QMDP
---

# QMDP

_Source page: 449_



, which derives its


ing (ICML)


, 1995. A proof that


name from the action value function associated with a fully observed MDP.


This


QMDP provides an upper bound


on the optimal value function is


approach, as well as several others discussed in this chapter, involve iteratively


given by M. Hauskrecht, “Value-


updating a set


of alpha vectors, as shown in algorithm 21.1. The resulting set


Function Approximations for Par-


defines a value function and a policy that can be used directly or with one-step


tially Observable Markov Decision


Processes,”


Journal of Artificial Intel-


lookahead as discussed in the previous chapter, though the resulting policy will


ligence Research


, vol. 13, pp. 33–94,


only be an approximation of the optimal solution.


2000.


Algorithm 21.1. Iteration structure


function


alphavector_iteration


::