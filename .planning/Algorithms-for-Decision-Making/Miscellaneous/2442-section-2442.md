---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: ) =
---

# ) =

_Source page: 391_



, as in the previous


section, then


is simply


Updating the parameter vector


thus requires both the discounted state


visitation frequency


and the optimal policy under the current parameter


vector,


. We can obtain the optimal policy by running reinforcement


learning. To compute the discounted state visitation frequencies, we can use


rollouts or take a dynamic programming approach.


If we take a dynamic programming approach to compute the discounted state


visitation frequencies, we can start with the initial state distribution


and iteratively work forward in time: