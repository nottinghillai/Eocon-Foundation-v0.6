---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: 10,000
---

# 10,000

_Source page: 617_



images


from the MNIST data set after training. Each encoding is colored according


to the corresponding digit:


10


We find that the digits tend to be clustered into regions that are roughly


radially distributed from the origin. Note how the encodings for


and


are


similar, as the two digits look alike. Recall that training is unsupervised, and


the network is not given any information about the digit values. Nevertheless,


these clusterings are produced.


Â© 2022 Massachusetts Institute of Technology, shared under a Creative Commons CC-BY-NC-ND license.


2025-09-21 10:49:56-07:00, comments to bugs@algorithmsbook.com


596


appendix d. neural representations


Example D.6. A visualization of


In example D.5, we trained an autoencoder on the MNIST data set. We can


two-dimensional


embedding


adapt the same network to produce two-dimensional mean and variance


learned


using


variational


autoencoder for the MNIST digits.


vectors at the bottleneck instead of a two-dimensional embedding, and then


Here, we show decoded outputs


train it to minimize both the reconstruction loss and the KL divergence. Here,


from inputs panned over the


we show the mean encodings for the same