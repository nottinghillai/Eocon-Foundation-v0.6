---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: MCTS
---

# MCTS

_Source page: 299_



Like the actor-critic method in the first section, we need to be able to compute the


gradient of our parameterized value function.


After performing some number of Monte Carlo tree search simulations, we


update


by stepping in the direction opposite to


and


by stepping in


The AlphaGo Zero implementa-


the direction opposite to


tion uses a single neural network


to represent both the value func-


tion and the policy instead of inde-