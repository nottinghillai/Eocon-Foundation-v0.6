---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: References
---

# References

_Source page: 673_



1.


P. Abbeel and A. Y. Ng, “Apprenticeship Learning via Inverse Reinforcement Learn-


ing,” in


International Conference on Machine Learning (ICML)


, 2004 (cit. on p. 361).


2.


J. Agar,


Science in the 20th Century and Beyond


. Polity, 2012 (cit. on p. 10).


3.


S. Amari, “Natural Gradient Works Efficiently in Learning,”


Neural Computation


vol. 10, no. 2, pp. 251–276, 1998 (cit. on p. 253).


4.


C. Amato, D. S. Bernstein, and S. Zilberstein, “Optimizing Fixed-Size Stochastic


Controllers for POMDPs and Decentralized POMDPs,”


Autonomous Agents and


Multi-Agent Systems


, vol. 21, no. 3, pp. 293–320, 2010 (cit. on pp. 478, 551).


5.


D. Amodei, C. Olah, J. Steinhardt, P. Christiano, J. Schulman, and D. Mané, “Con-


crete Problems in AI Safety,” 2016. arXiv: 1606.06565v2 (cit. on p. 13).


6.


P. Anand, “Are the Preference Axioms Really Rational?”


Theory and Decision


, vol. 23,


no. 2, pp. 189–214, 1987 (cit. on p. 112).


7.


D. Ariely,


Predictably Irrational: The Hidden Forces That Shape Our Decisions


. Harper,


2008 (cit. on p. 122).


8.


S. Arnborg, D. G. Corneil, and A. Proskurowski, “Complexity of Finding Embed-


dings in a


-Tree,”


SIAM Journal on Algebraic Discrete Methods


, vol. 8, no. 2, pp. 277–


284, 1987 (cit. on p. 52).


9.


M. S. Arulampalam, S. Maskell, N. Gordon, and T. Clapp, “A Tutorial on Particle


Filters for Online Nonlinear / Non-Gaussian Bayesian Tracking,”


IEEE Transactions


on Signal Processing


, vol. 50, no. 2, pp. 174–188, 2002 (cit. on p. 390).


10.


K. J. Åström, “Optimal Control of Markov Processes with Incomplete State Infor-


mation,”


Journal of Mathematical Analysis and Applications


, vol. 10, no. 1, pp. 174–205,


1965 (cit. on p. 407).


11.


P. Auer, N. Cesa-Bianchi, and P. Fischer, “Finite-Time Analysis of the Multiarmed


Bandit Problem,”


Machine Learning


, vol. 47, no. 2–3, pp. 235–256, 2002 (cit. on


p. 187).


652


references


12.


T. Ayer, O. Alagoz, and N. K. Stout, “A POMDP Approach to Personalize Mam-


mography Screening Decisions,”


Operations Research


, vol. 60, no. 5, pp. 1019–1034,


2012 (cit. on p. 4).


13.


H. Bai, D. Hsu, W. S. Lee, and V. A. Ngo, “Monte Carlo Value Iteration for Continuous-


State POMDPs,” in


International Workshop on the Algorithmic Foundations of Robotics