---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: Sequential Problems
---

# Sequential Problems

_Source page: 539_



MGs, also called


This chapter extends simple games to a sequential context with multiple states.


stochastic games


were originally studied in the 1950s


Markov game


MG


) can be viewed as a Markov decision process involving


around the same time as MDPs.


multiple agents with their own reward functions.


In this formulation, transitions


L. S. Shapley, “Stochastic Games,”


Proceedings of the National Academy


depend on the joint action and all agents seek to maximize their own reward. We


of Sciences


, vol. 39, no. 10, pp. 1095–


generalize the response models and the Nash equilibrium solution concept from


1100, 1953. They were introduced


into the multiagent artificial intel-


simple games to take into account the state transition model. The last part of this


ligence community decades later.


chapter discusses learning-based models, where the agents adapt their policies


M. L. Littman, “Markov Games as


based on information from observed interactions and knowledge of the reward


a Framework for Multi-Agent Re-


inforcement Learning,” in


Interna-


and transition functions.


tional Conference on Machine Learn-


ing (ICML)


, 1994.