---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: 75 %
---

# 75 %

_Source page: 261_



empirical quantiles of the estimates.


high variance


low variance


25


20


15


high bias


10


25


20


15


low bias


10


10


10


10


10


10


10


number of samples


number of samples


Â© 2022 Massachusetts Institute of Technology, shared under a Creative Commons CC-BY-NC-ND license.


2025-09-21 10:49:56-07:00, comments to bugs@algorithmsbook.com


240


chapter 11. policy gradient estimation


rewards across time steps. The


reward-to-go


approach attempts to reduce the


variance in the estimate.


To derive this approach, we begin by expanding equation (11.14):


!#