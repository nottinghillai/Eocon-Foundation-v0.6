---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: ) = (
---

# ) = (

_Source page: 419_



Exercise 19.2.


What is the belief update for a discrete POMDP with no observation? What


is the belief update for a POMDP with linear Gaussian dynamics with no observation?


Solution:


If an agent in a POMDP without an observation with belief


takes an action


the new belief


can be calculated as follows:


) =


) =


) =


This belief update is equivalent to having a uniform observation distribution. A POMDP


with linear Gaussian dynamics that has no observation will update its belief using only


the Kalman filter predict step in equation (19.12).


Exercise 19.3.


An autonomous vehicle represents its belief over its position using a mul-


tivariate normal distribution. It comes to a rest at a traffic light, and the belief updater


continues to run while it sits. Over time, the belief concentrates and becomes extremely


confident in a particular location. Why might this be a problem? How might this extreme


confidence be avoided?


© 2022 Massachusetts Institute of Technology, shared under a Creative Commons CC-BY-NC-ND license.


2025-09-21 10:49:56-07:00, comments to bugs@algorithmsbook.com


398


chapter 19. beliefs


Solution:


Overconfidence in a belief can be a problem when the models or belief updates


do not perfectly represent reality. The overconfident belief may have converged on a state


that does not match the true state. Once the vehicle moves again, new observations may


be inconsistent with the belief and result in poor estimates. To help address this issue, we


can require that the values of the diagonal elements of the covariance matrix be above


threshold.


Exercise 19.4.


Consider tracking our belief over the dud rate for widgets produced at a


factory. We use a Poisson distribution to model the probability that


duds are produced


in one day of factory operation given that the factory has a dud rate of


) =


Suppose that our initial belief over the dud rate follows a gamma distribution:


βλ


) =


where


0,


, and the belief is parameterized by the shape


and the rate


After a day of factory operation, we observe that


duds were produced. Show that


16


16


The gamma distribution is a con-


our updated belief over the dud rate is also a gamma distribution.


jugate prior to the Poisson distri-


Solution:


We seek the posterior distribution


, which we can obtain through


bution. A


conjugate prior


is a family


of probability distributions that re-


Bayes’ rule:


main within the same family when


updated with an observation. Con-


jugate priors are useful for model-


βλ


ing beliefs because their form re-


mains constant.


This is a gamma distribution:


) =


Exercise 19.5.


Why are particle filters with rejection not used for updating beliefs in


POMDPs with continuous observations?


Solution:


Rejection sampling requires repeatedly sampling the transition and observation


functions until the sampled observation matches the true observation. The probability


of sampling any particular value in a continuous probability distribution is zero, making


rejection sampling run forever. In practice, we would use a finite representation for contin-


uous values, such as


64


-bit floating point numbers, but rejection sampling can run for an


extremely long time for each particle.


© 2022 Massachusetts Institute of Technology, shared under a Creative Commons CC-BY-NC-ND license.


2025-09-21 10:49:56-07:00, comments to bugs@algorithmsbook.com


19.9. exercises


399


Exercise 19.6.


Explain why Spelunker Joe would not benefit from switching to a particle


filter with adaptive injection with


in example 19.5.


Solution:


Adaptive injection injects new particles when


. Spelunker Joe


slow


fast


assumes perfect observations and has a belief with particles that match his current obser-


vation. Thus, every particle has a weight of


, and both


. It follows


slow


are


fast


and


that


, leading to no new particles.


slow


is always


fast


Exercise 19.7.


Why is the injection rate scalar


in a particle filter with adaptive injection


typically not set to a value less than


Solution:


Particle injection was designed to inject particles when the current observations


have lower likelihood than a historic trend over the observation likelihood. Thus, injection


typically occurs only when the short-term estimate of the mean particle weight


fast


is less


than the long-term estimate of the mean particle weight


. If


, then particles can


slow


still be generated even if


, despite indicating that current observations have a


slow


fast


higher likelihood than the past average.


17


This problem was motivated by


Exercise 19.8.


Suppose we are dropped into a rectangular forest at an initial location


Richard Bellman’s ‘‘Lost in a For-


chosen uniformly at random. We do not know which direction we are facing. Fortunately,


est Problem,’’ in which we start at


17


we do know the dimensions of the forest (it has width


and length


).


We can


a random location and orientation


in a forest with a known geometry


move in a continuous path, continuously observing whether we are still in the forest.


and must find a policy that mini-


How can we apply belief updating to this problem? Here are three possible policies, each


mizes the average (or maximum)


defining a different path. Which of these policies are guaranteed to escape the forest?


time to exit. R. Bellman, “Minimiza-


Which policy is best?


tion Problem,”


Bulletin of the Amer-


ican Mathematical Society


, vol. 62,


no. 3, p. 270, 1956.


Two perpendicular segments,


A straight path of length


Two legs of an equilateral trian-


each of length


gle, each of length


Solution:


Our initial belief is a uniform distribution over all two-dimensional locations and


orientations (states) in the forest. We can represent an updated belief using the path that


we have traveled thus far. If we are still in the forest, our belief consists of all states that can


be reached from a state within the forest by following our path while remaining entirely


in the forest. As soon as we exit the forest, our belief consists of all states that reach the


edge by following our path while remaining entirely in the forest.


© 2022 Massachusetts Institute of Technology, shared under a Creative Commons CC-BY-NC-ND license.


2025-09-21 10:49:56-07:00, comments to bugs@algorithmsbook.com


400


chapter 19. beliefs


Of the given policies, only the last two are guaranteed to escape the forest. The path


formed by the two perpendicular segments and by the two sides of the equilateral triangle


will always intersect with the forest’s border. The straight segment, however, may not


leave the forest. We prefer the shorter of the two escaping policies, which is the equilateral


triangle.


Exercise 19.9.


Algorithm 19.2 checks whether the updated belief is a zero vector. When


can a belief update yield a zero vector? Why might this arise in real-world applications?


Solution:


A zero belief vector can result from an observation


that is considered impossible.


This situation can arise after taking action


from belief


when


) =


for all


possible next states


according to


and our transition model. Algorithm 19.2 handles


this case by returning a uniform belief. In practical applications, there may be a mismatch


between the model and the real world. We generally want to be careful to avoid assigning


zero probability to observations, just in case our belief, transition, or observations models


are incorrect.


Exercise 19.10.


Suppose we are performing in-flight monitoring of an aircraft. The aircraft


is either in a state of normal operation


or a state of malfunction


. We receive observa-


tions through the absence of a warning


or the presence of a warning


. We can choose


to allow the plane to continue to fly


or send the plane in for maintenance


. We have


the following transition and observation dynamics, where we assume that the warnings


are independent of the actions, given the status of the plane:


) =