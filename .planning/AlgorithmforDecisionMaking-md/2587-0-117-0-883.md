---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: 0.117, 0.883
---

# 0.117, 0.883

_Source page: 423_



Exercise 19.11.


Consider a robot moving along a line with position


, velocity


, and


acceleration


. At each time step, we directly control the acceleration and observe the


velocity. The equations of motion for the robot are


where


is the duration of each step. Suppose we would like to implement a Kalman filter


to update our belief. The state vector is


= [


. Determine


, and


Solution:


The transition and observation dynamics can be written in linear form as follows:


# "


Through these equations, we can identify


, and


Exercise 19.12.


Consider a robot with a differential drive moving in two dimensions at


a constant speed


. The robot’s state is its position


and its heading


. At each time


step, we control the robot’s turn rate


. The equations of motion for the robot are


cos


sin


© 2022 Massachusetts Institute of Technology, shared under a Creative Commons CC-BY-NC-ND license.


2025-09-21 10:49:56-07:00, comments to bugs@algorithmsbook.com


402


chapter 19. beliefs


This transition function is nonlinear. What is its linearization,


, as a function of the state


= [


Solution:


The linearization is given by the Jacobian as follows:


∂θ


sin














cos


∂θ


∂θ


∂θ


∂θ


∂θ


This linearization can be used in an extended Kalman filter to maintain a belief.


Exercise 19.13.


Suppose we choose the following


sigma points for an


-dimensional


distribution:


in


1 :


for


in


1 :


for


Show that we can reconstruct the mean and the covariance from these sigma points using


the weights


1/


Solution:


If we use the weights


1/


, the reconstructed mean is


and the reconstructed covariance is





)(





Exercise 19.14.


Recall the


sigma points and weights from the previous problem that


represent a mean


and covariance


. We would like to parameterize the sigma points and


weights in order to control the concentration of the points about the mean. Show that we


can construct a new set of sigma points by uniformly down-weighting the original sigma


points and then including the mean


as an additional sigma point. Show that this new


set of


sigma points matches the form in equation (19.23).


© 2022 Massachusetts Institute of Technology, shared under a Creative Commons CC-BY-NC-ND license.


2025-09-21 10:49:56-07:00, comments to bugs@algorithmsbook.com


19.9. exercises


403


Solution:


We can include the mean


in the sigma points from exercise 19.13 to obtain a


new set of


sigma points:


r


for


in


1 :


r


for


in


1 :


where


is the weight of the first sigma point. The weights of the remaining sigma points


are uniformly reduced from


1/


to


. The reconstructed mean is still


and the reconstructed covariance is still


We can vary


causes the


to produce different sets of sigma points. Setting


sigma points to spread away from the mean; setting


moves the sigma points


closer to the mean. This results in a scaled set of sigma points with different higher-order


moments, but it preserves the same mean and covariance.


We can match equation (19.23) by substituting


. It follows that


/2


1/


))


and


) =


Exercise 19.15.


Compute the set of sigma points and weights with


for a multivariate


Gaussian distribution with