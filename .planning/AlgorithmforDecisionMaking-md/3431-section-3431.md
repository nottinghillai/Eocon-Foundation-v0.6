---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: ) =
---

# ) =

_Source page: 568_



. A


In contrast with the complex-


Dec-POMDP with joint full observability is called a


decentralized Markov decision


ity classes NP and PSPACE, it


process


Dec-MDP


). Both Dec-POMDP and Dec-MDP problems are


NEXP-complete


is known that NEXP is not in P.


when the number of steps in the horizon is fewer than the number of states.


Hence, we can prove that Dec-


MDPs and Dec-POMDPs do not


In many settings, the state space of a Dec-POMDP is factored, one for each


allow for polynomial time algo-


agent and one for the environment. This is called a


factored Dec-POMDP


. We


rithms. D. S. Bernstein, R. Givan,


N. Immerman, and S. Zilberstein,


have