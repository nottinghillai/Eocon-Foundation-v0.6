---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: (15.3)
---

# (15.3)

_Source page: 328_



where


is the number of times that we have taken action


, and


The parameter


controls the amount of exploration that is encouraged


through the second term. Larger values of


lead to more exploration. This strategy


is often used with maximum likelihood estimates of the payoff probabilities, but


we can adapt it to the Bayesian context by having


be the sum of the beta


distribution parameters associated with


Another general approach to exploration is to use


posterior sampling


(algo-


rithm 15.8), also referred to as


randomized probability matching


or


Thompson sam-


W. R. Thompson, “On the Like-


pling


It is simple to implement and does not require careful parameter tuning.


lihood That One Unknown Prob-


The idea is to sample from the posterior distribution over the rewards associated


ability Exceeds Another in View


with the various actions. The action with the largest sampled value is selected.


of the Evidence of Two Samples,”


Biometrika


, vol. 25, no. 3/4, pp. 285–


294, 1933. For a recent tutorial, see


D. Russo, B. V. Roy, A. Kazerouni,