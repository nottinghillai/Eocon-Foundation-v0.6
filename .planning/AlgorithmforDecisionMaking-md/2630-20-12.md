---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: (20.12)
---

# (20.12)

_Source page: 433_



The optimal value function for


making the value function piecewise-linear and convex.


continuous-state POMDPs is also


An alternative to using a conditional plan to represent a policy is to use a set


convex, as can be seen by approxi-


of alpha vectors


, each annotated with an action. Although it is not practical,


mating the POMDP through state


space discretization and taking the


one way to generate set


is to enumerate the set of


-step conditional plans and


limit as the number of discrete


then compute their alpha vectors. The action associated with an alpha vector


states approaches infinity.


is the action at the root of the associated conditional plan. We execute a policy


represented by


by updating our belief state and performing the action associated


with the dominating alpha vector at the new belief


. The dominating alpha vector


at


is the one that maximizes


. This strategy can be used to select actions


© 2022 Massachusetts Institute of Technology, shared under a Creative Commons CC-BY-NC-ND license.


2025-09-21 10:49:56-07:00, comments to bugs@algorithmsbook.com


412


chapter 20. exact belief state planning


beyond the horizon of the original conditional plans. Algorithm 20.4 provides an


implementation.


Algorithm 20.4. An alpha vector


struct


AlphaVectorPolicy


policy is defined in terms of a set


# POMDP problem


of alpha vectors


and an array of


# alpha vectors


associated actions


. Given the cur-


# actions associated with alpha vectors


rent belief


, it will find the alpha


end


vector that gives the highest value


function


utility


::


AlphaVectorPolicy


at that belief point. It will return


return


maximum


α⋅b


for


in


the associated action.


end


function


::


AlphaVectorPolicy


)(


argmax


([


α⋅b


for


in


])


return


end


If we use


one-step lookahead


, we do not have to keep track of the actions associated


with the alpha vectors in


. The one-step lookahead action from belief


using


the value function represented by


, denoted as


, is