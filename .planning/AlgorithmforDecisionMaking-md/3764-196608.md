---
converted: '2025-10-25'
source: AlgorithmforDecisionMaking.pdf
title: 196,608
---

# 196,608

_Source page: 609_



entries. Any fully connected layer taking


an


image as input and producing a vector of


outputs would have


Figure D.6. Multidimensional in-


a weight matrix with


values. The large number of parameters to learn is


puts like images generalize vectors


to tensors. Here, we show a three-


not only computationally expensive, it is also wasteful. Information in images


layer RGB image. Such inputs can


is typically translation-invariant; an object in an image that is shifted right by


have very many entries.


pixel should produce a similar, if not identical, output.


Y. LeCun, L. Bottou, Y. Bengio,


Convolutional layers


both significantly reduce the amount of computation and


and P. Haffner, “Gradient-Based


support translation invariance by sliding a smaller, fully connected window to


Learning Applied to Document


produce their output. Significantly fewer parameters need to be learned. These


Recognition,”


Proceedings of the